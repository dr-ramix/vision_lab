# ============================================================================
# Training entry point (train.py)
#
# Usage:
#   python train.py key=value key=value ...
#
# Example:
#   python train.py model=resnet18 epochs=30 bs=64 lr=3e-4
#   python train.py model=emonext loss=emonext mix_prob=0.5 mixup_alpha=0.8
#   python train.py model=convnextferbase label_smoothing=0.1 ema=true ema_decay=0.9999
#
# ---------------------------------------------------------------------------
# Common CLI parameters (key=value)
#
#  model              (str)   default="resnet18"
#    - Model architecture key (from fer.models.registry)
#    - Change to: emonext, convnextferbase, coatnet, ...
#
#  epochs             (int)   default=30
#    - Number of training epochs
#    - Increase if training has not converged
#
#  bs                 (int)   default=64
#    - Batch size
#    - Limited by GPU memory
#
#  lr                 (float) default=3e-4
#    - Learning rate
#    - Most important hyperparameter to tune
#
#  optimizer          (str)   default="adamw"
#    - adamw | adam | sgd | rmsprop | adagrad | adamax | nadam
#
#  scheduler          (str)   default="cosine"
#    - cosine | step | exp | plateau | none
#
#  class_weight       (bool)  default=True
#    - Use class-weighted loss for imbalanced datasets
#
#  label_smoothing    (float) default=0.0
#    - Softens labels (0.05–0.1 often improves generalization)
#
#  loss               (str)   default="ce"
#    - ce | emonext
#    - Use emonext for EmoNeXt models
#
#  mix_prob           (float) default=0.0
#    - Probability of applying MixUp / CutMix per batch
#
#  mixup_alpha        (float) default=0.0
#    - MixUp strength (typical: 0.4–0.8)
#
#  cutmix_alpha       (float) default=0.0
#    - CutMix strength (typical: 0.5–1.0)
#
#  ema                (bool)  default=False
#    - Enable Exponential Moving Average of model weights
#
#  ema_decay          (float) default=0.0
#    - EMA decay factor (typical: 0.9999)
#
#  select_metric      (str)   default="accuracy"
#    - Metric used to select best checkpoint
#    - Options: accuracy | f1_macro | f1_weighted | ...
#
#  preview_split      (str)   default="test"
#    - Which split to visualize (train | val | test)
#
# ---------------------------------------------------------------------------
# All outputs are written to:
#   <output_root>/runs/<timestamp>__<model>__<...>/
#
# Including:
#   - checkpoints (best.pt, last.pt)
#   - metrics & confusion matrices
#   - logs (csv/json)
#   - previews (annotated predictions)
#   - exports (state_dict, TorchScript)
# ============================================================================
